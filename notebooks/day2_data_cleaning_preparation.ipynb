{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5508c77",
      "metadata": {
        "id": "c5508c77"
      },
      "source": [
        "# ðŸ“… Day 2 â€” Data Cleaning & Preparation\n",
        "\n",
        "*RTU Data Analysis & Visualization CPD course*\n",
        "\n",
        "**ðŸ“š Instruction (3h)**  \n",
        "- ðŸ§¹ Handling missing values  \n",
        "- ðŸ—‘ Removing duplicates  \n",
        "- ðŸ”„ Data type conversion  \n",
        "- ðŸ“… Parsing dates  \n",
        "- ðŸ— Feature engineering basics  \n",
        "- ðŸ”— Combining datasets  \n",
        "- ðŸ· Intro to categorical encoding  \n",
        "\n",
        "**ðŸ›  Practical (1h)**  \n",
        "- ðŸ§½ Clean a messy dataset  \n",
        "- ðŸ”€ Merge with a secondary dataset  \n",
        "\n",
        "**ðŸ”„ Reflection (1h)**  \n",
        "- ðŸ§ Review: common pitfalls in cleaning  \n",
        "- ðŸ’¬ Discuss real-world cleaning challenges  \n",
        "- ðŸ“ Recap exercise: identify cleaning steps for a small example dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea319510",
      "metadata": {
        "id": "ea319510"
      },
      "source": [
        "## ðŸŽ¯ Goals for the Day\n",
        "- Strengthen Python basics (functions, loops, if/else, file handling)\n",
        "- Learn to process raw messy text files into usable form\n",
        "- Apply pandas methods to clean incomplete/messy data\n",
        "- Merge multiple datasets into a single unified dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d16816f",
      "metadata": {
        "id": "9d16816f"
      },
      "source": [
        "## ðŸ’¡ Motivation / Explanation\n",
        "\n",
        "### Introduction to Data Cleaning and Preparation\n",
        "\n",
        "- **Why cleaning is critical before analysis**\n",
        "  - Raw data is almost never ready for direct analysis\n",
        "  - Errors, inconsistencies, and missing information can distort results\n",
        "  - Proper cleaning ensures reliability, reproducibility, and trust in analysis outcomes\n",
        "\n",
        "- **Real-world examples of messy data**\n",
        "  - ðŸ§¹ Handling missing values - Weather records with missing timestamps or corrupt values\n",
        "  - ðŸ—³ï¸ Survey responses with inconsistent categories (e.g., \"Male\", \"male\", \"M\")\n",
        "  - ðŸ—‘ Removing duplicates - Financial transactions with duplicate entries\n",
        "  - ðŸ—‘ Log files with noise lines, system messages, or broken encodings\n",
        "  - ðŸ“… Parsing dates - Event logs with inconsistent timestamp formats\n",
        "  - ðŸ”„ Data type conversion - User age recorded as text instead of numbers\n",
        "\n",
        "> Think of data cleaning as *â€œwashing vegetables before cookingâ€* â€” not exciting, but essential for a good meal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5432cd86",
      "metadata": {
        "id": "5432cd86"
      },
      "source": [
        "## Weather Dataset: `latvia_meteo_1925_messy.zip`\n",
        "\n",
        "Let us imagine we are helping Toms Bricis with weather data analysis for the year 1925. We have come across a bundle of messy text files that require cleaning and preparation.\n",
        "\n",
        "- **What it is:** a bundle of **five â€œmessyâ€ text files** (â‰ˆ50 rows each) simulating daily measurements from Latvian stations in **1925**:\n",
        "  - **RÄ«ga-University** â€” *Period 1 (Janâ€“Mar)*\n",
        "  - **RÄ«ga-University** â€” *Period 2 (Sepâ€“Nov)*\n",
        "  - **LiepÄja** â€” *Aprâ€“Jun*\n",
        "  - **MÄ“rsrags** â€” *Febâ€“May*\n",
        "  - **AlÅ«ksne** â€” *Octâ€“Dec*\n",
        "\n",
        "- **Columns present (but order varies by file):**  \n",
        "  `date`, `t_max_c`, `t_min_c`, `precip_24h_mm`, `precip_type`, `present_weather_code`, `notes`\n",
        "\n",
        "- **Deliberate â€œmessinessâ€ to practice cleaning:**\n",
        "  - **Different separators:** `;`, `,`, `|`, and **TAB** (documented in each fileâ€™s `# fields=` header).\n",
        "  - **Mixed column order** across files (use the header to map columns).\n",
        "  - **Date formats vary** (`YYYY-MM-DD`, `DD.MM.YYYY`, `YYYY/MM/DD`, `DD-MM-YYYY`, `MM-DD-YYYY`, `YYYY.MM.DD`) and sometimes **include a time** (e.g., `07:00`).\n",
        "  - **Numeric quirks:** decimal **commas** (e.g., `0,6`), **units** in strings (e.g., `0.8 mm`), and the Latvian word **â€œnulleâ€** for zero.\n",
        "  - **Missing values** sprinkled in as `\"\"`, `NA`, `â€”`, `-999`.\n",
        "  - **Codes as strings** with possible leading zeros (e.g., `present_weather_code = \"05\"`).\n",
        "  - **Free-text `notes`** in Latvian from the station master (may be blank/missing).\n",
        "\n",
        "- **Intended skills to practice (Day 2):**\n",
        "  - Detect & use **separators/column order** from headers.\n",
        "  - **Parse heterogeneous dates** (with optional times).\n",
        "  - Normalize **numerics/units** (decimal commas, `mm`, worded zeros).\n",
        "  - Unify **missing values** and enforce **types** (e.g., cast weather codes to integers).\n",
        "  - Keep useful **categorical text** (`precip_type`, `notes`) intact.\n",
        "\n",
        "As part of our workflow we will want to verify whether the above descriptions of messiness hold true for our specific dataset files. This will help us tailor our cleaning approach effectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec9faea",
      "metadata": {
        "id": "eec9faea"
      },
      "source": [
        "## Part 1: Python Fundamentals for Data Cleaning\n",
        "\n",
        "For our first part we will use basic Python programming skills to explore and understand the dataset structure before diving into the cleaning process.\n",
        "\n",
        "### ðŸ”‘ Key Idea - Loops Go Brrr\n",
        "\n",
        "One of key advantages of programming is that we can automate repetitive tasks using loops. This is especially useful when working with datasets, as it allows us to apply the same operations to multiple rows or files without having to write redundant code.\n",
        "\n",
        "Similarly loops let us figure out an approach that works for a single file and then easily adapt it to others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ecad9f",
      "metadata": {
        "id": "85ecad9f"
      },
      "source": [
        "### Getting ready for work\n",
        "\n",
        "Typically in a finished notebook (and also normal scripts / programs), we want to start with a clear setup phase. This includes:\n",
        "\n",
        "1. **Importing Libraries:** Load all necessary libraries at the beginning.\n",
        "2. **Setting Up Paths:** Define file paths and other constants.\n",
        "3. **Configuring Options:** Set any options or preferences (e.g., display settings).\n",
        "\n",
        "By organizing our code this way, we make it easier to understand and modify later on.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a4ca0466",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ca0466",
        "outputId": "b3c1ccfa-f62c-44c2-bb2e-20b723c29040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today : 2025-08-20T15:22:55\n",
            "Python : 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "pandas: 2.2.2\n",
            "Runtime: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "Total Current Drive Space: 107.72 GB\n",
            "Free Current Drive Space: 68.94 GB\n",
            "Current Working Directory: /content\n"
          ]
        }
      ],
      "source": [
        "# usually we start with general Python imports\n",
        "from pathlib import Path # for file and file path related tasks\n",
        "import sys, platform, os, io, shutil, zipfile, re # system related tasks\n",
        "from datetime import datetime\n",
        "# first datetime\n",
        "print(f\"Today : {datetime.now().isoformat(timespec='seconds')}\")\n",
        "# now Python version\n",
        "print(f\"Python : {sys.version}\")\n",
        "\n",
        "# then we import external libraries\n",
        "# external - not part of Python installation\n",
        "# on Google Colab those are already installed\n",
        "try:\n",
        "    import pandas as pd\n",
        "    print('pandas:', pd.__version__)\n",
        "except ImportError:\n",
        "    print(f\"pandas not installed. Install with `pip install pandas`.\")\n",
        "    # for excel support extra instructions\n",
        "    print(f\"Install `openpyxl` for Excel support with `pip install openpyxl`.\")\n",
        "# requests is a widely used network library that makes internet \"requests\" easier\n",
        "try:\n",
        "    import requests\n",
        "except ImportError:\n",
        "    requests = None\n",
        "    print('requests not installed. Install with `pip install requests`.')\n",
        "\n",
        "\n",
        "# we can also print out what type of environment we are running in, this could show OS information\n",
        "print('Runtime:', platform.platform())\n",
        "# We could show system RAM and free RAM but that would require either a non standard library\n",
        "# or we would have to write some extra functions we skip this for now\n",
        "# you can ask LLM to write these functions for you\n",
        "# alternatively there are external libraries like psutil that do this out of the box\n",
        "\n",
        "# Let us show our current drive space\n",
        "print(f\"Total Current Drive Space: {shutil.disk_usage('/').total / (1024**3):.2f} GB\")\n",
        "print(f\"Free Current Drive Space: {shutil.disk_usage('/').free / (1024**3):.2f} GB\")\n",
        "\n",
        "# Current Working Directory\n",
        "print(f\"Current Working Directory: {Path.cwd()}\")\n",
        "# note that in some cases you might not want to provide all this information to the public, if you have a super secret computer...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e523062c",
      "metadata": {
        "id": "e523062c"
      },
      "source": [
        "### ðŸ§‘â€ðŸ’» Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dff1d21"
      },
      "source": [
        "### What is the idea behind functions in programming?\n",
        "\n",
        "In programming, a function is a block of reusable code that performs a specific task. Think of it like a miniature program within your main program. Functions are designed to:\n",
        "\n",
        "- **Break down complex problems:** Large problems can be divided into smaller, manageable parts, each handled by a function. This makes code easier to write, understand, and debug.\n",
        "- **Avoid repetition (DRY principle - Don't Repeat Yourself):** If you need to perform the same set of actions multiple times, you can define a function once and call it whenever needed, rather than writing the same code repeatedly.\n",
        "- **Improve code organization and readability:** Functions group related code together, making the overall structure of your program clearer and easier to follow.\n",
        "- **Enhance code reusability:** Once a function is defined, it can be used in different parts of the same program or even in other programs.\n",
        "- **Simplify debugging:** If there's an issue, you can isolate the problem to a specific function, making it easier to find and fix the error.\n",
        "\n",
        "In essence, functions are tools for modularity and abstraction in programming, allowing you to create more organized, efficient, and maintainable code.\n",
        "\n",
        "### What is a function in Python?\n",
        "\n",
        "In Python, a function is defined using the `def` keyword, followed by the function name, parentheses `()`, and a colon `:`. The code block within the function is indented. Functions can optionally take inputs called *arguments* (placed inside the parentheses) and can return a value using the `return` keyword.\n",
        "\n",
        "Here's a basic structure of a Python function:"
      ],
      "id": "6dff1d21"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d94c3040",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d94c3040",
        "outputId": "7bee570a-fbf9-4f79-e39c-52c6eacdadb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, student!\n"
          ]
        }
      ],
      "source": [
        "def greet(name: str = 'student') -> str:\n",
        "    \"\"\"\n",
        "    Returns a friendly greeting for the given name.\n",
        "    If no name is provided, defaults to 'student'.\n",
        "    \"\"\"\n",
        "    # Use an f-string to insert the name into the greeting\n",
        "    return f\"Hello, {name}!\" # we can insert pretty much any type of data in f-strings\n",
        "\n",
        "# Call the function and print the result\n",
        "greeting = greet() # assign results of greet() function to greeting variable\n",
        "print(greeting)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that I have this function I can make other greetings\n",
        "my_greeting = greet(\"Valdis\")\n",
        "print(my_greeting)\n",
        "numeric_greeting = greet(808) # function expects str, but no penalty in this case\n",
        "print(numeric_greeting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGWKzOyzG-BT",
        "outputId": "d143ab90-7114-4b2c-e357-c1cd2d2ac989"
      },
      "id": "DGWKzOyzG-BT",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Valdis!\n",
            "Hello, 808!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to download and unzip file from url"
      ],
      "metadata": {
        "id": "eE3hLZ5nIBAX"
      },
      "id": "eE3hLZ5nIBAX"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f4b2f894",
      "metadata": {
        "id": "f4b2f894"
      },
      "outputs": [],
      "source": [
        "def download_and_unzip(url: str, target_folder: str | Path = 'sample_data') -> Path:\n",
        "    \"\"\"\n",
        "    Downloads a ZIP file from the given URL and extracts it to the target folder.\n",
        "    Returns the path to the folder where files were extracted.\n",
        "    \"\"\"\n",
        "    target = Path(target_folder)  # Make sure target is a Path object\n",
        "    target.mkdir(parents=True, exist_ok=True)  # Create the folder if it doesn't exist\n",
        "    filename = url.split('/')[-1]  # Get the file name from the URL\n",
        "    # in case of URL the file name is the last one (so index -1 means last one in a list)\n",
        "    # next we create full path where we will save the zip file\n",
        "    zip_path = target / filename  # Full path to save the ZIP file\n",
        "    # check if library exists\n",
        "    if requests is None:\n",
        "        raise RuntimeError('requests required.')\n",
        "    # Download the file in chunks (good for large files)\n",
        "    with requests.get(url, stream=True, timeout=60) as r:\n",
        "        r.raise_for_status()  # Raise an error if download failed\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    # Unzip the downloaded file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "        zf.extractall(target) # this command given a zip file as target will unzip ALL files\n",
        "    # Optionally, remove the ZIP file after extraction\n",
        "    # zip_path.unlink(missing_ok=True)  # Remove the ZIP file\n",
        "    return target  # Return the folder where files were extracted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "369862d6",
      "metadata": {
        "id": "369862d6"
      },
      "source": [
        "**Practice dataset for Part 1:** `latvia_meteo_1925_messy.zip` (5 text files)\n",
        "\n",
        "- URL: https://github.com/ValRCS/RTU_Data_Analysis_Visualization_CPD/raw/refs/heads/main/data/latvia_meteo_1925_messy.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c941a28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c941a28",
        "outputId": "91862ec8-71fd-432c-a6d0-aec43d5f1115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will download and unzip from following url: https://github.com/ValRCS/RTU_Data_Analysis_Visualization_CPD/raw/refs/heads/main/data/latvia_meteo_1925_messy.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('day_2_data')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# let's download the messy files zip\n",
        "url = \"https://github.com/ValRCS/RTU_Data_Analysis_Visualization_CPD/raw/refs/heads/main/data/latvia_meteo_1925_messy.zip\"\n",
        "print(f\"Will download and unzip from following url: {url}\")\n",
        "# let's download the file and extract it under day_2_data\n",
        "download_and_unzip(url, Path(\"day_2_data\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's add Google Colab specific code that will offer download to your computer of all the files extracted\n",
        "from google.colab import files # this is Google Colab specific\n",
        "# if you were local you would already have these files locally\n",
        "for p in sorted(Path(\"day_2_data\").glob(\"*.txt\")): # glob looks in current folder\n",
        "    files.download(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zVxkQR7yK88c",
        "outputId": "adb268e9-bae0-44a2-def1-aa51bafce90c"
      },
      "id": "zVxkQR7yK88c",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03b3df5e-6882-4766-8e32-32f6388aad45\", \"aluksne_1925.txt\", 2033)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8abf2ed8-fd22-408f-82a8-2b986c8ae230\", \"liepaja_1925.txt\", 2077)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8b1ba123-78d4-4ea8-831a-c7eaca540ea0\", \"mersrags_1925.txt\", 2537)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60f84e3a-e9fe-4e48-b82e-b95b7a3818c4\", \"riga_university_1925_p1.txt\", 2006)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4dd17be7-ca37-492d-aded-b78fef4bde5a\", \"riga_university_1925_p2.txt\", 1908)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b153f8c3",
      "metadata": {
        "id": "b153f8c3"
      },
      "source": [
        "[link text](https://)### ðŸ“‚ File Handling\n",
        "\n",
        "First let me show you how to read whole text file into one big text string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make a function that takes a file Path or string and optional encoding with default utf-8 and returns text string\n",
        "def get_file_contents(path: Path | str, encoding: str = 'utf-8') -> str:\n",
        "    \"\"\"\n",
        "    Reads the contents of a text file and returns it as a string.\n",
        "    \"\"\"\n",
        "    # so path could be string or Path\n",
        "    # file could have any extension but it should contain text of some sort\n",
        "    with open(path, 'r', encoding=encoding) as f:\n",
        "        return f.read()"
      ],
      "metadata": {
        "id": "B2M3mbQ_PZCq"
      },
      "id": "B2M3mbQ_PZCq",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's read aluksne into memory\n",
        "# aluksne = get_file_contents(Path(\"day_2_data/aluksne_1925.txt\"))\n",
        "aluksne = get_file_contents(\"day_2_data/aluksne_1925.txt\")\n",
        "print(aluksne)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwAhyXkoP19P",
        "outputId": "f977acb3-d252-4053-fd66-0d47a656b45d"
      },
      "id": "qwAhyXkoP19P",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# station_name=AlÅ«ksne\n",
            "# period=(Octâ€“Dec)\n",
            "# separator_hint=|\n",
            "# columns_in_this_file= notes | present_weather_code | t_max_c | precip_24h_mm | date | precip_type | t_min_c\n",
            "# note: some values intentionally messy (units, words, missing, time in date)\n",
            "# fields=notes|present_weather_code|t_max_c|precip_24h_mm|date|precip_type|t_min_c\n",
            "â€”|53|5.9|3.0 mm|10-19-1925|R|5.5\n",
            "RÄ«ts auksts|-999|9.1|2.3 mm|18.10.1925|mixed|4.2\n",
            "DaÄ¼Ä“ji mÄkoÅ†ains|65|5.4|0.0|11-10-1925||-0.5\n",
            "DaÄ¼Ä“ji mÄkoÅ†ains|50|15.6|0.5|10-07-1925 14:00|S|10.4\n",
            "Neliels vÄ“jÅ¡|63|-1.1|0.0|12-28-1925|â€”|â€”\n",
            "VÄ“lÄk sÄka lÄ«t|-999|5.3||12-07-1925 19:00|none|\n",
            "PÅ«tis brÄzmas|82|4.2|0.6 mm|11-07-1925|S|0.1\n",
            "â€”|61|-7.2|1.4|12-03-1925|mixed|-6.5\n",
            "Laikam migla|51|3.3|1.0 mm|11-27-1925|mixed|-1.3\n",
            "MÄ“rÄ«Å¡anas kÄ¼Å«da?|70|-3.5999999999999996|2.1|12-06-1925|M|-2.9\n",
            "SkursteÅ†i kÅ«p|71|6.2|0.0|10-21-1925||6.9\n",
            "NA|61|1.3|2.1|28.11.1925|NA|2.0\n",
            "Ap pusdienlaiku saule|80|8.4|1.9 mm|02-11-1925|snow|-1.5\n",
            "|53|8.4||10-01-1925 07:00||3.3\n",
            "MÄ“rÄ«jums apstiprinÄts|53|10.8|0.7 mm|10-08-1925|S|5.3\n",
            "RÄ«ts auksts|45|8.1|0.1|1925-11-25|NA|-999\n",
            "Laikam migla|53|8.9|2.5|10-17-1925 07:00|R|7.1\n",
            "NA||5.4|0.8|11-22-1925 19:00|snow|2.7\n",
            "|82|1.1|0.9|12-25-1925 08:00|S|-4.5\n",
            "â€”|65||0.0 mm|10-23-1925|none|-0.4\n",
            "DaÄ¼Ä“ji mÄkoÅ†ains|60|9.1|1.7|10-02-1925|S|1.6\n",
            "PÅ«tis brÄzmas|80|10.3|nulle|10-16-1925 14:00|â€”|7.9\n",
            "PÅ«tis brÄzmas|61|6.0|0.2 mm|11-24-1925 14:00|snow|-1.9\n",
            "MÄ“rÄ«jums apstiprinÄts|45|2.9|1.1 mm|12-14-1925 19:00||-6.6\n",
            "Laikam migla|82|9.0|0.0|10-10-1925||3.9\n",
            "|63|3.9|1.7 mm|12-02-1925|S|-2.3\n",
            "Ap pusdienlaiku saule|81|2.3|0.0 mm|11-03-1925 20:00|NA|1.4\n",
            "â€”|53|-3.0|0.6|12-13-1925|mixed|-4.0\n",
            "RÄ«ts auksts|73|12.3|1.9|10-20-1925|mixed|-999\n",
            "DaÄ¼Ä“ji mÄkoÅ†ains|51||3.5 mm|11-06-1925 08:00|M|-4.6\n",
            "VÄ“lÄk sÄka lÄ«t|60|NA|1.1 mm|11-20-1925|M|1.8\n",
            "MÄ“rÄ«jums apstiprinÄts|51|-2.2|0.2 mm|12-18-1925|snow|-7.6\n",
            "PÅ«tis brÄzmas|82|5.3||11-18-1925||-0.4\n",
            "NA|63|3.4||12-19-1925|M|-6.0\n",
            "NovÄ“rojums vÄ“lÄk|90|-0.2|2.3|12-22-1925|mixed|-8.2\n",
            "DaÄ¼Ä“ji mÄkoÅ†ains|90|-3.5|0.2 mm|12-16-1925|rain|-4.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterating over file line at a time\n",
        "\n",
        "Above example showed how we could read a whole file into memory.\n",
        "However that means we would be working with file as one big string as a whole. We could do some replace operations.\n",
        "\n",
        "Much more often we will want to work on file one line(row) at a time."
      ],
      "metadata": {
        "id": "Xu2zQhslRDSd"
      },
      "id": "Xu2zQhslRDSd"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "85ef7c4c",
      "metadata": {
        "id": "85ef7c4c"
      },
      "outputs": [],
      "source": [
        "def iter_lines(path: Path | str):\n",
        "    \"\"\"\n",
        "    Yields each line from a text file, removing the newline character at the end.\n",
        "    Useful for reading files line by line.\n",
        "    \"\"\"\n",
        "    # Open the file for reading (UTF-8 encoding, replace errors)\n",
        "    with open(path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        for line in f:\n",
        "            yield line.rstrip('\\n')  # Remove the newline at the end of each line\n",
        "            # why yield? # because it allows processing each line one at a time, which is more memory efficient"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87dc72f9",
      "metadata": {
        "id": "87dc72f9"
      },
      "source": [
        "### ðŸ”„ For Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ae3f7301",
      "metadata": {
        "id": "ae3f7301"
      },
      "outputs": [],
      "source": [
        "def count_lines(path: Path) -> tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Counts the total number of lines and the number of non-empty lines in a file.\n",
        "    Returns a tuple: (total_lines, nonempty_lines)\n",
        "    \"\"\"\n",
        "    total, nonempty = 0, 0  # Initialize counters\n",
        "    for line in iter_lines(path):  # Go through each line in the file\n",
        "        total += 1\n",
        "        if line.strip():  # Check if the line is not just whitespace\n",
        "            nonempty += 1\n",
        "    return total, nonempty # this is how we return two values at once in Python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's count lines in aluksne_1925\n",
        "count_lines(Path(\"day_2_data/aluksne_1925.txt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOyraEVYRpDS",
        "outputId": "97cf47a0-0aec-45ea-ad06-88aea12b292d"
      },
      "id": "lOyraEVYRpDS",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc944702",
      "metadata": {
        "id": "bc944702"
      },
      "source": [
        "### ðŸŒ³ If / Else Branching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7a30ab34",
      "metadata": {
        "id": "7a30ab34"
      },
      "outputs": [],
      "source": [
        "# note how the function is called is_\n",
        "def is_good_line(line: str) -> bool:\n",
        "    \"\"\"\n",
        "    Checks if a line of text is 'good' (not empty, not a comment, and long enough).\n",
        "    Returns True if the line is good, False otherwise.\n",
        "    \"\"\"\n",
        "    s = line.strip()  # Remove whitespace from both ends\n",
        "    # so now s is a string of text - possibly empty \"\" or something but without whitespace (\\n, \\t, at left or right side)\n",
        "    if not s: return False  # Skip empty lines\n",
        "    if s.startswith('#'): return False  # Skip comment lines\n",
        "    if len(s) < 5: return False  # Skip very short lines, this is an assumption\n",
        "    # you could add any logic you want here\n",
        "    # idea is that if we checked everything bad possible, then we return True meaning this is a good line\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82debebc",
      "metadata": {
        "id": "82debebc"
      },
      "source": [
        "### ðŸ§¹ Building a Cleaning Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2499e44f",
      "metadata": {
        "id": "2499e44f"
      },
      "outputs": [],
      "source": [
        "def clean_file(path: Path) -> tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Reads a file and writes 'good' lines to one file and 'bad' lines to another.\n",
        "    Returns a tuple: (number_of_good_lines, number_of_bad_lines)\n",
        "    \"\"\"\n",
        "    out_good = path.with_suffix('.good.txt')  # Output file for good lines\n",
        "    out_bad = path.with_suffix('.bad.txt')    # Output file for bad lines\n",
        "    good, bad = 0, 0  # Counters for good and bad lines\n",
        "    # Open the input and output files\n",
        "    # the cool thing is that this recipe only opens file one row at a time\n",
        "    # so you could work on files that do not fit in your memory even multi TB files\n",
        "    with path.open('r', encoding='utf-8', errors='replace') as fin, \\\n",
        "         out_good.open('w') as fg, out_bad.open('w') as fb:\n",
        "        # so we loop through the input text file one row/line at a time\n",
        "        # very memory efficient\n",
        "        for line in fin:\n",
        "            if is_good_line(line):\n",
        "                fg.write(line)  # Write good line\n",
        "                good += 1\n",
        "            else:\n",
        "                fb.write(line)  # Write bad line\n",
        "                bad += 1\n",
        "    # we do not have to return anything in Python then we return None by default\n",
        "    return good, bad  # Return the counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try running it on aluksne_1925.txt\n",
        "clean_file(Path(\"day_2_data/aluksne_1925.txt\"))"
      ],
      "metadata": {
        "id": "egIQU_QsWTqR",
        "outputId": "bae42bb8-d5c9-4525-9184-1b9c23e71dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "egIQU_QsWTqR",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778e34eb",
      "metadata": {
        "id": "778e34eb"
      },
      "source": [
        "### ðŸ“ Extending to Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b32f02e9",
      "metadata": {
        "id": "b32f02e9"
      },
      "outputs": [],
      "source": [
        "def clean_files(folder: Path):\n",
        "    \"\"\"\n",
        "    Cleans all .txt files in the given folder using clean_file().\n",
        "    Returns a dictionary with file paths as keys and (good, bad) counts as values.\n",
        "    \"\"\"\n",
        "    results = {}  # Dictionary to store results for each file\n",
        "    for file in folder.glob('*.txt'):\n",
        "        if \"good\" in file.name or \"bad\" in file.name: continue  # Skip already processed files # this means I do not do anything with this file\n",
        "        # TODO good practice would but \"good\" \"bad\" as parameters\n",
        "        results[file] = clean_file(file)  # Clean each file and store the result\n",
        "    return results # we return a dictionary of results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's run it day_2_data folder\n",
        "results = clean_files(Path(\"day_2_data\"))"
      ],
      "metadata": {
        "id": "i9fEF3qhYZMD"
      },
      "id": "i9fEF3qhYZMD",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "fde5iOXCYqeo",
        "outputId": "218f2e86-a0f1-4e51-f5ff-545c1a1e89ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fde5iOXCYqeo",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{PosixPath('day_2_data/aluksne_1925.txt'): (36, 6),\n",
              " PosixPath('day_2_data/liepaja_1925.txt'): (36, 6),\n",
              " PosixPath('day_2_data/riga_university_1925_p2.txt'): (36, 6),\n",
              " PosixPath('day_2_data/mersrags_1925.txt'): (48, 6),\n",
              " PosixPath('day_2_data/riga_university_1925_p1.txt'): (36, 6)}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb1b335",
      "metadata": {
        "id": "0cb1b335"
      },
      "source": [
        "## Determining the separator character\n",
        "\n",
        "Our files have helpfully provided a separator hint without which it would be very hard to determine.\n",
        "\n",
        "`# separator_hint=|`\n",
        "`# separator_hint=TAB`\n",
        "`# separator_hint=,`\n",
        "\n",
        "Let's write a function that extracts hint from the file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5f354afe",
      "metadata": {
        "id": "5f354afe"
      },
      "outputs": [],
      "source": [
        "def get_sep(path: Path) -> str:\n",
        "    \"\"\"\n",
        "    We look for first line that contains\n",
        "    `# separator_hint=|`\n",
        "`# separator_hint=TAB`\n",
        "`# separator_hint=,`\n",
        "    \"\"\"\n",
        "    needle = \"separator_hint=\"\n",
        "    sep = None # we start with assumption that we do not know the separator\n",
        "    # lets open file and go through line by line\n",
        "    with open(path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        for line in f:\n",
        "            if needle in line: # we check for presence of needle\n",
        "            # we could have used regular expression but no need here\n",
        "                # let's find whatever is after needle\n",
        "                # so we split by needle at take last part\n",
        "                sep = line.split(needle)[-1].strip()\n",
        "    # if sep is TAB we need to return \\t\n",
        "    if sep == \"TAB\": # special case TAB which we need to convert\n",
        "        return \"\\t\"\n",
        "    return sep"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see if we can find separator for aluksne_1925\n",
        "get_sep(Path(\"day_2_data/aluksne_1925.txt\"))"
      ],
      "metadata": {
        "id": "dMQsAaEyaCtd",
        "outputId": "2ffc63f6-d731-462e-96be-78891432c692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "dMQsAaEyaCtd",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's find it for all txt files that do not contain good or bad\n",
        "for p in sorted(Path(\"day_2_data\").glob(\"*.txt\")):\n",
        "    if \"good\" in p.name or \"bad\" in p.name: continue\n",
        "    # we could have used bad as well\n",
        "    print(p, get_sep(p))"
      ],
      "metadata": {
        "id": "XvUvlg5zaRzg",
        "outputId": "bc0d2e4f-3e1e-495e-8414-d3ff8f7fb24e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XvUvlg5zaRzg",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day_2_data/aluksne_1925.txt |\n",
            "day_2_data/liepaja_1925.txt ,\n",
            "day_2_data/mersrags_1925.txt \t\n",
            "day_2_data/riga_university_1925_p1.txt ;\n",
            "day_2_data/riga_university_1925_p2.txt ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "177a338f",
      "metadata": {
        "id": "177a338f"
      },
      "source": [
        "### ðŸ“¥ Loading Cleaned Files into DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1164b480",
      "metadata": {
        "id": "1164b480"
      },
      "outputs": [],
      "source": [
        "# we might want to supply our own separator\n",
        "\n",
        "def load_cleaned_file(path: Path, sep: str = \",\") -> pd.DataFrame:\n",
        "    with path.open('r') as f:\n",
        "        lines = [l.strip().split(sep) for l in f if l.strip()]\n",
        "    maxlen = max(len(r) for r in lines) if lines else 0\n",
        "    cols = [f'col{i+1}' for i in range(maxlen)] if maxlen else []\n",
        "    return pd.DataFrame(lines, columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's test if we get dataframe on liepaja_1925.txt\n",
        "liepaja_df = load_cleaned_file(Path(\"day_2_data/liepaja_1925.good.txt\"))\n",
        "liepaja_df"
      ],
      "metadata": {
        "id": "9XAbM9QLbOOt",
        "outputId": "d9926f97-b934-414e-b262-6270867d2189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "9XAbM9QLbOOt",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    col1             col2              col3   col4  col5  col6  \\\n",
              "0     13                2        1925/05/26   none    75     0   \n",
              "1     24                4        07.06.1925   rain    75     0   \n",
              "2     12  600000000000001        1925/05/20      S    50     0   \n",
              "3     15                8        1925/06/16           73     0   \n",
              "4     21                9  1925/06/25 07:00      â€”    81     0   \n",
              "5     17                1        1925/05/25  mixed    81     2   \n",
              "6      7                4        1925/04/16   snow    90     1   \n",
              "7      5                0  1925/04/17 13:00      R    90         \n",
              "8              1925/05/23                       80        -999   \n",
              "9     17                1        1925/05/18   none    82  -999   \n",
              "10    12                9        1925/06/24     NA    90     1   \n",
              "11     5                3  1925/04/28 20:00     NA    45         \n",
              "12    22                9        1925/06/23   rain    82     0   \n",
              "13  -999       1925/04/03                 M     63     0     6   \n",
              "14     6                0        1925/04/06      S    90         \n",
              "15    19                9        1925/06/19      â€”    82     0   \n",
              "16    12  100000000000001  1925/06/15 20:00   rain    82     1   \n",
              "17     8                1  1925/04/22 08:00  mixed  -999     1   \n",
              "18    20                7        1925/06/03      â€”    50     0   \n",
              "19    10                2  1925/04/05 20:00      â€”    81     0   \n",
              "20    17                4        1925/06/10   rain    70     0   \n",
              "21     8                9        1925/05/02   none     â€”     0   \n",
              "22  -999       1925/04/04                 R     81     1  5 mm   \n",
              "23     8                8        1925/05/10           70     0   \n",
              "24    14                8  1925/06/06 19:00      S    55     1   \n",
              "25  -999       05-15-1925                NA            0  0 mm   \n",
              "26    12                3  1925/04/13 19:00      R    80     0   \n",
              "27     â€”       1925/04/14                 R     80     0     6   \n",
              "28    18                7        1925/05/07           65     0   \n",
              "29    17                2        1925/05/09      R    80     0   \n",
              "30    10                8        1925/04/24      S    65     0   \n",
              "31    21                4  1925/06/09 14:00  mixed    55     1   \n",
              "32    17                3        1925/05/16   -999     â€”     0   \n",
              "33    11                9        1925/04/15      â€”    82     0   \n",
              "34  -999       27.05.1925              none     60     0     0   \n",
              "35    17                8        1925/06/18      â€”    73     0   \n",
              "\n",
              "                     col7              col8                   col9  \\\n",
              "0                    0 mm              -999       MÄ“rÄ«Å¡anas kÄ¼Å«da?   \n",
              "1                       6                16                      8   \n",
              "2                    4 mm                13                      3   \n",
              "3                       2                10                      8   \n",
              "4                    0 mm                15                      4   \n",
              "5                    4 mm                 9                      1   \n",
              "6                    5 mm                NA                     NA   \n",
              "7                       5                 7           Neliels vÄ“jÅ¡   \n",
              "8   MÄ“rÄ«jums apstiprinÄts              None                   None   \n",
              "9                      10                 5  Ap pusdienlaiku saule   \n",
              "10                   3 mm                13                      6   \n",
              "11                     NA  NovÄ“rojums vÄ“lÄk                   None   \n",
              "12                   6 mm                NA  Ap pusdienlaiku saule   \n",
              "13                      â€”      Neliels vÄ“jÅ¡                   None   \n",
              "14                      5                 9  MÄ“rÄ«jums apstiprinÄts   \n",
              "15                      9                16                      5   \n",
              "16                   8 mm                12                      8   \n",
              "17                   8 mm                 4                      3   \n",
              "18                      0                17                      4   \n",
              "19                   1 mm                 1                      3   \n",
              "20                      6                 5                      2   \n",
              "21                      0                 9                      6   \n",
              "22                      5                 9       MÄ“rÄ«Å¡anas kÄ¼Å«da?   \n",
              "23                   0 mm                 9                      5   \n",
              "24                      8                 9                      5   \n",
              "25                      7                 5            RÄ«ts auksts   \n",
              "26                      5                 4                      7   \n",
              "27                      3                 7  Ap pusdienlaiku saule   \n",
              "28                      0                 8                      8   \n",
              "29                      2                NA       NovÄ“rojums vÄ“lÄk   \n",
              "30                      6                 5                      5   \n",
              "31                      1                12                      8   \n",
              "32                   2 mm                 6                      0   \n",
              "33                      7                 3                      6   \n",
              "34                      â€”                 â€”                   None   \n",
              "35                      0                11                      5   \n",
              "\n",
              "                    col10  \n",
              "0                    None  \n",
              "1            Neliels vÄ“jÅ¡  \n",
              "2           PÅ«tis brÄzmas  \n",
              "3           SkursteÅ†i kÅ«p  \n",
              "4                      NA  \n",
              "5        DaÄ¼Ä“ji mÄkoÅ†ains  \n",
              "6                    None  \n",
              "7                    None  \n",
              "8                    None  \n",
              "9                    None  \n",
              "10                     NA  \n",
              "11                   None  \n",
              "12                   None  \n",
              "13                   None  \n",
              "14                   None  \n",
              "15            Sniegs kÅ«st  \n",
              "16           Laikam migla  \n",
              "17            RÄ«ts auksts  \n",
              "18           Laikam migla  \n",
              "19          SkursteÅ†i kÅ«p  \n",
              "20           Laikam migla  \n",
              "21           Laikam migla  \n",
              "22                   None  \n",
              "23           Laikam migla  \n",
              "24                     NA  \n",
              "25                   None  \n",
              "26       MÄ“rÄ«Å¡anas kÄ¼Å«da?  \n",
              "27                   None  \n",
              "28  Ap pusdienlaiku saule  \n",
              "29                   None  \n",
              "30                     NA  \n",
              "31  MÄ“rÄ«jums apstiprinÄts  \n",
              "32                      â€”  \n",
              "33                         \n",
              "34                   None  \n",
              "35       MÄ“rÄ«Å¡anas kÄ¼Å«da?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24b0cc1c-b315-42a7-a0aa-c9de8992b07a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col1</th>\n",
              "      <th>col2</th>\n",
              "      <th>col3</th>\n",
              "      <th>col4</th>\n",
              "      <th>col5</th>\n",
              "      <th>col6</th>\n",
              "      <th>col7</th>\n",
              "      <th>col8</th>\n",
              "      <th>col9</th>\n",
              "      <th>col10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1925/05/26</td>\n",
              "      <td>none</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>0 mm</td>\n",
              "      <td>-999</td>\n",
              "      <td>MÄ“rÄ«Å¡anas kÄ¼Å«da?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>07.06.1925</td>\n",
              "      <td>rain</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>Neliels vÄ“jÅ¡</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>600000000000001</td>\n",
              "      <td>1925/05/20</td>\n",
              "      <td>S</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>4 mm</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>PÅ«tis brÄzmas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>1925/06/16</td>\n",
              "      <td></td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>SkursteÅ†i kÅ«p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>1925/06/25 07:00</td>\n",
              "      <td>â€”</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>0 mm</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1925/05/25</td>\n",
              "      <td>mixed</td>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "      <td>4 mm</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>DaÄ¼Ä“ji mÄkoÅ†ains</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1925/04/16</td>\n",
              "      <td>snow</td>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>5 mm</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1925/04/17 13:00</td>\n",
              "      <td>R</td>\n",
              "      <td>90</td>\n",
              "      <td></td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>Neliels vÄ“jÅ¡</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>1925/05/23</td>\n",
              "      <td></td>\n",
              "      <td>80</td>\n",
              "      <td></td>\n",
              "      <td>-999</td>\n",
              "      <td>MÄ“rÄ«jums apstiprinÄts</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1925/05/18</td>\n",
              "      <td>none</td>\n",
              "      <td>82</td>\n",
              "      <td>-999</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>Ap pusdienlaiku saule</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>1925/06/24</td>\n",
              "      <td>NA</td>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>3 mm</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1925/04/28 20:00</td>\n",
              "      <td>NA</td>\n",
              "      <td>45</td>\n",
              "      <td></td>\n",
              "      <td>NA</td>\n",
              "      <td>NovÄ“rojums vÄ“lÄk</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>1925/06/23</td>\n",
              "      <td>rain</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>6 mm</td>\n",
              "      <td>NA</td>\n",
              "      <td>Ap pusdienlaiku saule</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-999</td>\n",
              "      <td>1925/04/03</td>\n",
              "      <td>M</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>â€”</td>\n",
              "      <td>Neliels vÄ“jÅ¡</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1925/04/06</td>\n",
              "      <td>S</td>\n",
              "      <td>90</td>\n",
              "      <td></td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>MÄ“rÄ«jums apstiprinÄts</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>1925/06/19</td>\n",
              "      <td>â€”</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>Sniegs kÅ«st</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>12</td>\n",
              "      <td>100000000000001</td>\n",
              "      <td>1925/06/15 20:00</td>\n",
              "      <td>rain</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>8 mm</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>Laikam migla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1925/04/22 08:00</td>\n",
              "      <td>mixed</td>\n",
              "      <td>-999</td>\n",
              "      <td>1</td>\n",
              "      <td>8 mm</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>RÄ«ts auksts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>1925/06/03</td>\n",
              "      <td>â€”</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>Laikam migla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1925/04/05 20:00</td>\n",
              "      <td>â€”</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>1 mm</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>SkursteÅ†i kÅ«p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>1925/06/10</td>\n",
              "      <td>rain</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>Laikam migla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>1925/05/02</td>\n",
              "      <td>none</td>\n",
              "      <td>â€”</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>Laikam migla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-999</td>\n",
              "      <td>1925/04/04</td>\n",
              "      <td>R</td>\n",
              "      <td>81</td>\n",
              "      <td>1</td>\n",
              "      <td>5 mm</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>MÄ“rÄ«Å¡anas kÄ¼Å«da?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1925/05/10</td>\n",
              "      <td></td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0 mm</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>Laikam migla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>1925/06/06 19:00</td>\n",
              "      <td>S</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>-999</td>\n",
              "      <td>05-15-1925</td>\n",
              "      <td>NA</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0 mm</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>RÄ«ts auksts</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1925/04/13 19:00</td>\n",
              "      <td>R</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>MÄ“rÄ«Å¡anas kÄ¼Å«da?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>â€”</td>\n",
              "      <td>1925/04/14</td>\n",
              "      <td>R</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Ap pusdienlaiku saule</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>18</td>\n",
              "      <td>7</td>\n",
              "      <td>1925/05/07</td>\n",
              "      <td></td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>Ap pusdienlaiku saule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>1925/05/09</td>\n",
              "      <td>R</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NA</td>\n",
              "      <td>NovÄ“rojums vÄ“lÄk</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>1925/04/24</td>\n",
              "      <td>S</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>1925/06/09 14:00</td>\n",
              "      <td>mixed</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>MÄ“rÄ«jums apstiprinÄts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>1925/05/16</td>\n",
              "      <td>-999</td>\n",
              "      <td>â€”</td>\n",
              "      <td>0</td>\n",
              "      <td>2 mm</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>â€”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>1925/04/15</td>\n",
              "      <td>â€”</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>-999</td>\n",
              "      <td>27.05.1925</td>\n",
              "      <td>none</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>â€”</td>\n",
              "      <td>â€”</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>1925/06/18</td>\n",
              "      <td>â€”</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>MÄ“rÄ«Å¡anas kÄ¼Å«da?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24b0cc1c-b315-42a7-a0aa-c9de8992b07a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24b0cc1c-b315-42a7-a0aa-c9de8992b07a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24b0cc1c-b315-42a7-a0aa-c9de8992b07a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a542e00f-7049-4aa4-8342-e0031061940d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a542e00f-7049-4aa4-8342-e0031061940d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a542e00f-7049-4aa4-8342-e0031061940d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ccf7873f-c899-4f31-a28c-ac9ddb86ad9c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('liepaja_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ccf7873f-c899-4f31-a28c-ac9ddb86ad9c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('liepaja_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "liepaja_df",
              "summary": "{\n  \"name\": \"liepaja_df\",\n  \"rows\": 36,\n  \"fields\": [\n    {\n      \"column\": \"col1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"13\",\n          \"\\u2014\",\n          \"10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"2\",\n          \"4\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35,\n        \"samples\": [\n          \"1925/04/13 19:00\",\n          \"M\",\n          \"1925/06/06 19:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"NA\",\n          \"81\",\n          \"none\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col5\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"75\",\n          \"50\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col6\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"2\",\n          \"6\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col7\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"0 mm\",\n          \"7\",\n          \"1 mm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col8\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"-999\",\n          \"3\",\n          \"8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col9\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"M\\u0113r\\u012b\\u0161anas k\\u013c\\u016bda?\",\n          \"8\",\n          \"NA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col10\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"\\u2014\",\n          \"Ap pusdienlaiku saule\",\n          \"Neliels v\\u0113j\\u0161\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first let's get all good.txt files as list\n",
        "good_files = sorted(Path(\"day_2_data\").glob(\"*.good.txt\"))\n",
        "good_files\n"
      ],
      "metadata": {
        "id": "J50o98aIcd2v",
        "outputId": "51033c04-f6b1-41bf-ff74-4ea4efd11afc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J50o98aIcd2v",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('day_2_data/aluksne_1925.good.txt'),\n",
              " PosixPath('day_2_data/liepaja_1925.good.txt'),\n",
              " PosixPath('day_2_data/mersrags_1925.good.txt'),\n",
              " PosixPath('day_2_data/riga_university_1925_p1.good.txt'),\n",
              " PosixPath('day_2_data/riga_university_1925_p2.good.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's convert atll Paths to strings\n",
        "good_files = [str(p) for p in good_files]\n",
        "good_files\n"
      ],
      "metadata": {
        "id": "_uJWT-cheS4D",
        "outputId": "90cd47b4-6cf1-4a52-8ed2-1fddaf527a19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_uJWT-cheS4D",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['day_2_data/aluksne_1925.good.txt',\n",
              " 'day_2_data/liepaja_1925.good.txt',\n",
              " 'day_2_data/mersrags_1925.good.txt',\n",
              " 'day_2_data/riga_university_1925_p1.good.txt',\n",
              " 'day_2_data/riga_university_1925_p2.good.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for each good file find matching bad file meaning suffix bad.txt instead of good.txt\n",
        "bad_files = [p.replace('.good.txt', '.bad.txt') for p in good_files]\n",
        "bad_files"
      ],
      "metadata": {
        "id": "oa-RAhfYdiUT",
        "outputId": "70c146dc-4791-44e1-bfe4-becc7f19a439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oa-RAhfYdiUT",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['day_2_data/aluksne_1925.bad.txt',\n",
              " 'day_2_data/liepaja_1925.bad.txt',\n",
              " 'day_2_data/mersrags_1925.bad.txt',\n",
              " 'day_2_data/riga_university_1925_p1.bad.txt',\n",
              " 'day_2_data/riga_university_1925_p2.bad.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's convert all bad_files back to path\n",
        "bad_files = [Path(p) for p in bad_files]\n",
        "bad_files"
      ],
      "metadata": {
        "id": "p1NIGWxPec0I",
        "outputId": "308cf1f9-edd6-4156-b626-67b4c5589fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p1NIGWxPec0I",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('day_2_data/aluksne_1925.bad.txt'),\n",
              " PosixPath('day_2_data/liepaja_1925.bad.txt'),\n",
              " PosixPath('day_2_data/mersrags_1925.bad.txt'),\n",
              " PosixPath('day_2_data/riga_university_1925_p1.bad.txt'),\n",
              " PosixPath('day_2_data/riga_university_1925_p2.bad.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check if these bad files exist\n",
        "for p in bad_files:\n",
        "    print(p, p.exists())"
      ],
      "metadata": {
        "id": "0o-vcQrNdrgA",
        "outputId": "45e8e9cd-2061-44b7-da5e-4d0124ce2fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0o-vcQrNdrgA",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day_2_data/aluksne_1925.bad.txt True\n",
            "day_2_data/liepaja_1925.bad.txt True\n",
            "day_2_data/mersrags_1925.bad.txt True\n",
            "day_2_data/riga_university_1925_p1.bad.txt True\n",
            "day_2_data/riga_university_1925_p2.bad.txt True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's convert good_files back to Paths as well\n",
        "good_files = [Path(p) for p in good_files]\n",
        "good_files"
      ],
      "metadata": {
        "id": "nxzukuuLer3d",
        "outputId": "c0c69365-a3ec-4675-8df6-016caaadd99b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nxzukuuLer3d",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('day_2_data/aluksne_1925.good.txt'),\n",
              " PosixPath('day_2_data/liepaja_1925.good.txt'),\n",
              " PosixPath('day_2_data/mersrags_1925.good.txt'),\n",
              " PosixPath('day_2_data/riga_university_1925_p1.good.txt'),\n",
              " PosixPath('day_2_data/riga_university_1925_p2.good.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so now let us iterate (loop) through both lists of files at the same time\n",
        "# we will extract separator from bad text file and extract DataFrame from good text file\n",
        "# we will store Dataframes in a dictionary\n",
        "dataframe_dict = {}\n",
        "for good, bad in zip(good_files, bad_files): # so we take one item at a time from each list of items\n",
        "    sep = get_sep(bad)\n",
        "    print(f\"Voila found separator {sep} in {bad} file\")\n",
        "    dataframe_dict[good.stem] = load_cleaned_file(good, sep=sep)\n",
        "\n",
        "# print size of dictionary\n",
        "print(f\"Dictionary size: {len(dataframe_dict)}\")"
      ],
      "metadata": {
        "id": "uhxGNFVXe88q",
        "outputId": "f571faa3-4222-41fa-d137-da87efeea17b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uhxGNFVXe88q",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voila found separator | in day_2_data/aluksne_1925.bad.txt file\n",
            "Voila found separator , in day_2_data/liepaja_1925.bad.txt file\n",
            "Voila found separator \t in day_2_data/mersrags_1925.bad.txt file\n",
            "Voila found separator ; in day_2_data/riga_university_1925_p1.bad.txt file\n",
            "Voila found separator ; in day_2_data/riga_university_1925_p2.bad.txt file\n",
            "Dictionary size: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let us see what keys we have in our dictionary\n",
        "dataframe_dict.keys()"
      ],
      "metadata": {
        "id": "SgMi4d26fo4g",
        "outputId": "8d0a9eca-e90e-4b7b-9ff5-341007eb9e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SgMi4d26fo4g",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['aluksne_1925.good', 'liepaja_1925.good', 'mersrags_1925.good', 'riga_university_1925_p1.good', 'riga_university_1925_p2.good'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let us print shape of each DateFrame\n",
        "for key, value in dataframe_dict.items():\n",
        "    print(f\"Dataframe {key} has shape {value.shape}\")"
      ],
      "metadata": {
        "id": "kePjG8ZMf3oD",
        "outputId": "d562fa8f-b383-445a-81db-99d8d7035eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kePjG8ZMf3oD",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe aluksne_1925.good has shape (36, 7)\n",
            "Dataframe liepaja_1925.good has shape (36, 10)\n",
            "Dataframe mersrags_1925.good has shape (48, 7)\n",
            "Dataframe riga_university_1925_p1.good has shape (36, 7)\n",
            "Dataframe riga_university_1925_p2.good has shape (36, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let us save all dataframes as excel files\n",
        "for key, value in dataframe_dict.items():\n",
        "    value.to_excel(f\"{key}.xlsx\")"
      ],
      "metadata": {
        "id": "FJwlO-tvgH5g"
      },
      "id": "FJwlO-tvgH5g",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on Colab let us download all xlsx files in current directory\n",
        "from google.colab import files\n",
        "for p in sorted(Path(\".\").glob(\"*.xlsx\")):\n",
        "    files.download(p)"
      ],
      "metadata": {
        "id": "y4IZn3ufgCef",
        "outputId": "dc56496a-4b0f-43ae-dbbe-5a0506e1008b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "id": "y4IZn3ufgCef",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d9fa9ab7-9315-4947-9b59-ec70c6d9193a\", \"aluksne_1925.good.xlsx\", 6876)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9d93fa2c-1a51-464d-99b4-b98e8c009d37\", \"liepaja_1925.good.xlsx\", 7254)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1d35d090-eb83-45f4-ba0a-0609ac46abbf\", \"mersrags_1925.good.xlsx\", 7365)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_01d55c57-a768-4203-8b9d-71815412f9c0\", \"riga_university_1925_p1.good.xlsx\", 6799)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be36f5bc-221b-4cb3-95ac-5d7f9b27634d\", \"riga_university_1925_p2.good.xlsx\", 6793)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08925dbe",
      "metadata": {
        "id": "08925dbe"
      },
      "source": [
        "## Part 2: Guided Exercise â€” Latvia Weather Data (Extra Messy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d71e5dda",
      "metadata": {
        "id": "d71e5dda"
      },
      "source": [
        "**Duration:** ~30 minutes  \n",
        "**Dataset:** `latvia_meteo_1925_extra_messy.zip`  \n",
        "**URL:** https://github.com/ValRCS/RTU_Data_Analysis_Visualization_CPD/raw/refs/heads/main/data/latvia_meteo_1925_extra_messy.zip\n",
        "\n",
        "### ðŸŽ¯ Objective\n",
        "Convert multiple extra-messy weather text files into **one cleaned file per source**, then load each into a **separate DataFrame**.\n",
        "\n",
        "### âœ… Success Criteria\n",
        "- Each original text file has a corresponding `.good.txt` output.\n",
        "- Each `.good.txt` loads into a DataFrame without errors.\n",
        "- Basic column consistency achieved (same number of columns and sensible types where possible).\n",
        "\n",
        "### ðŸ” What to Watch For\n",
        "- Junk header/footer lines (e.g., comments, separators)\n",
        "- Inconsistent separators (`,`, `;`, tabs, or spaces)\n",
        "- Missing fields and short/empty lines\n",
        "- Non-UTF8 characters â€” use `errors='replace'` if needed\n",
        "\n",
        "### ðŸ§­ Suggested Workflow\n",
        "1) **Download & unzip** to `data/` using `download_and_unzip`  \n",
        "2) **List files** and do a quick **line count** with `count_lines`  \n",
        "3) **Clean** with `clean_files(data_dir)`  \n",
        "4) **Load** each cleaned file with `load_cleaned_file`  \n",
        "5) **Sanity-check**: `.head()`, `.info()`, and simple value counts on key columns\n",
        "\n",
        "### ðŸ§© Hints\n",
        "- If a file still fails to parse, adjust `is_good_line` (e.g., skip lines that start with specific tokens).\n",
        "- If different files use different separators, handle at **pandas** stage later (Part 3) by re-parsing columns.\n",
        "- Keep outputs organized: write cleaned files into a `data/cleaned/` subfolder if you choose to extend `clean_files`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d0ea1f",
      "metadata": {
        "id": "95d0ea1f"
      },
      "outputs": [],
      "source": [
        "# --- SKELETON (students fill in) ---\n",
        "EXTRA_URL = 'https://github.com/ValRCS/RTU_Data_Analysis_Visualization_CPD/raw/refs/heads/main/data/latvia_meteo_1925_extra_messy.zip'\n",
        "DATA_DIR = Path('data')\n",
        "\n",
        "# 1) Download & unzip\n",
        "# download_and_unzip(EXTRA_URL, DATA_DIR)\n",
        "\n",
        "# 2) Inspect: list files & counts\n",
        "# for p in sorted(DATA_DIR.glob('*.txt')):\n",
        "#     print(p.name, '->', count_lines(p))\n",
        "\n",
        "# 3) Clean all files\n",
        "# results = clean_files(DATA_DIR)\n",
        "# results\n",
        "\n",
        "# 4) Load cleaned files\n",
        "# dfs_extra = {}\n",
        "# for p in sorted(DATA_DIR.glob('*.good.txt')):\n",
        "#     dfs_extra[p.stem] = load_cleaned_file(p)\n",
        "# {k: v.head() for k, v in dfs_extra.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e6fd3a",
      "metadata": {
        "id": "96e6fd3a"
      },
      "source": [
        "### ðŸ§ª Checkpoints\n",
        "- At least **Nâ‰¥3** cleaned files successfully load into DataFrames.\n",
        "- No parsing exceptions on `.head()` or `.info()`.\n",
        "- You can explain (in comments) which rules your `is_good_line` used.\n",
        "\n",
        "### ðŸ›  Extension (Optional)\n",
        "- Write a variant `clean_files(folder, out_dir=Path('data/cleaned'))` that writes outputs into a subfolder.\n",
        "- Add a **regex-based** `is_good_line_regex` that only keeps lines starting with `YYYY-MM-DD`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89a410b",
      "metadata": {
        "id": "f89a410b"
      },
      "source": [
        "## Part 3: Pandas-Specific Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99b764b0",
      "metadata": {
        "id": "99b764b0"
      },
      "source": [
        "### Overview\n",
        "In this section, you will standardize each DataFrame from Part 2 so they share a **common schema** and are ready to merge.\n",
        "\n",
        "### Target Schema (example)\n",
        "- `date` (datetime)\n",
        "- `station` (string/category)\n",
        "- `t_min` (float)\n",
        "- `t_max` (float)\n",
        "- `precip` (float)\n",
        "\n",
        "### Typical Operations\n",
        "1. **Column detection & renaming** â€“ bring different column names to a shared set\n",
        "2. **Type coercion** â€“ numbers via `pd.to_numeric(errors='coerce')`, dates via `pd.to_datetime(errors='coerce')`\n",
        "3. **Missing values** â€“ `dropna` or `fillna` depending on context\n",
        "4. **Duplicates** â€“ `.duplicated()` + `.drop_duplicates()`\n",
        "5. **Categoricals** â€“ normalize text (`strip`, `title`, `upper`) and `astype('category')` if useful\n",
        "6. **Validation** â€“ quick assertions (e.g., date not null, temperature ranges plausible)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1972b8ec",
      "metadata": {
        "id": "1972b8ec"
      },
      "source": [
        "### Step-by-Step Guide\n",
        "1) **Pick one DataFrame** from `dfs_extra` and print `.head()`, `.columns`, `.info()`\n",
        "2) **Map columns** to target names (e.g., `temp_min` â†’ `t_min`)\n",
        "3) **Coerce**:\n",
        "   - `date = pd.to_datetime(df['date'], errors='coerce')`\n",
        "   - `df[['t_min','t_max','precip']] = df[['t_min','t_max','precip']].apply(pd.to_numeric, errors='coerce')`\n",
        "4) **Handle missing**: start conservative (e.g., drop rows missing `date` or all temperature columns)\n",
        "5) **Standardize station names**: `df['station'] = df['station'].astype(str).str.strip().str.title()`\n",
        "6) **Check duplicates** and remove\n",
        "7) **Repeat** for all DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc449af",
      "metadata": {
        "id": "8dc449af"
      },
      "source": [
        "### Common Pitfalls & Tips\n",
        "- Treat ambiguous `-` or `NA` strings as missing (`na_values=[\"-\",\"NA\",\"N/A\"]` if you re-read with `read_csv`)\n",
        "- Some files might have **merged columns**; split using `.str.split(',', expand=True)` when necessary\n",
        "- If a file lacks a column, create it with `pd.NA` so the schema lines up later"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe28061",
      "metadata": {
        "id": "afe28061"
      },
      "source": [
        "### ðŸ§± Skeleton: Inspect & Rename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f16bfb3c",
      "metadata": {
        "id": "f16bfb3c"
      },
      "outputs": [],
      "source": [
        "# Example skeleton for one dataframe named df\n",
        "# df = dfs_extra['some_file']\n",
        "# print(df.head()); print(df.columns); df.info()\n",
        "\n",
        "# rename_map = {\n",
        "#     'Date': 'date', 'DATE':'date',\n",
        "#     'Station':'station', 'City':'station',\n",
        "#     'Tmin':'t_min', 'TminC':'t_min', 'Min':'t_min',\n",
        "#     'Tmax':'t_max', 'TmaxC':'t_max', 'Max':'t_max',\n",
        "#     'Precip':'precip', 'Rain':'precip'\n",
        "# }\n",
        "# df = df.rename(columns=lambda c: rename_map.get(str(c), str(c).strip().lower()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6b255cc",
      "metadata": {
        "id": "d6b255cc"
      },
      "source": [
        "### ðŸ§± Skeleton: Type Coercion & Missing Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19ef475",
      "metadata": {
        "id": "a19ef475"
      },
      "outputs": [],
      "source": [
        "# required_cols = ['date','station','t_min','t_max','precip']\n",
        "# for c in required_cols:\n",
        "#     if c not in df.columns:\n",
        "#         df[c] = pd.NA\n",
        "\n",
        "# df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "# for c in ['t_min','t_max','precip']:\n",
        "#     df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "# # Drop rows with no usable date\n",
        "# df = df.dropna(subset=['date'])\n",
        "\n",
        "# # Optional: fill precip missing with 0 if domain-appropriate\n",
        "# # df['precip'] = df['precip'].fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e69ada3",
      "metadata": {
        "id": "6e69ada3"
      },
      "source": [
        "### ðŸ§± Skeleton: Text Normalization & Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6537d71d",
      "metadata": {
        "id": "6537d71d"
      },
      "outputs": [],
      "source": [
        "# df['station'] = df['station'].astype(str).str.strip().str.title()\n",
        "# before = len(df)\n",
        "# df = df.drop_duplicates()\n",
        "# print('Removed', before - len(df), 'duplicate rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db547327",
      "metadata": {
        "id": "db547327"
      },
      "source": [
        "### ðŸ§ª Suggested Sanity Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67435a09",
      "metadata": {
        "id": "67435a09"
      },
      "outputs": [],
      "source": [
        "# assert df['date'].notna().all(), 'Null dates remain'\n",
        "# # Optional plausibility checks (adjust to real units)\n",
        "# assert (df['t_min'] <= df['t_max']).dropna().all(), 'Found t_min > t_max'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc1e041",
      "metadata": {
        "id": "fbc1e041"
      },
      "source": [
        "## Part 4: Merging Cleaned DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d818314",
      "metadata": {
        "id": "2d818314"
      },
      "source": [
        "### Goal\n",
        "Combine all standardized DataFrames into **one big DataFrame** with a **unified column structure**.\n",
        "\n",
        "### Strategy\n",
        "1. **Define the target schema** used in Part 3.\n",
        "2. **Align each DataFrame** to the schema (add missing columns, reorder).\n",
        "3. **Concatenate** with `pd.concat`.\n",
        "4. **Final cleanup**: deduplicate, reindex, and sort by date/station.\n",
        "5. **Save outputs** (`CSV` or `Parquet`) for Day 3 (EDA)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ee0bea",
      "metadata": {
        "id": "65ee0bea"
      },
      "source": [
        "### Integration Checklist\n",
        "- All DataFrames have columns: `date, station, t_min, t_max, precip`\n",
        "- Dtypes are consistent across DataFrames\n",
        "- No catastrophic loss of rows during coercion\n",
        "- Final row count equals the sum of inputs minus duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2d282b",
      "metadata": {
        "id": "4a2d282b"
      },
      "source": [
        "### ðŸ§± Skeleton: Alignment & Concatenation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de996ea9",
      "metadata": {
        "id": "de996ea9"
      },
      "outputs": [],
      "source": [
        "# Suppose you have a dict of cleaned dfs: dfs_clean\n",
        "# target_cols = ['date','station','t_min','t_max','precip']\n",
        "\n",
        "# def coerce_to_schema(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
        "#     for c in cols:\n",
        "#         if c not in df.columns:\n",
        "#             df[c] = pd.NA\n",
        "#     # Reorder and drop extras for now\n",
        "#     return df[cols]\n",
        "\n",
        "# aligned = [coerce_to_schema(d.copy(), target_cols) for d in dfs_clean.values()]\n",
        "# big = pd.concat(aligned, axis=0, ignore_index=True)\n",
        "# big = big.drop_duplicates().reset_index(drop=True)\n",
        "# big = big.sort_values(['date','station'])\n",
        "# big.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2821858",
      "metadata": {
        "id": "d2821858"
      },
      "source": [
        "### ðŸ§¾ Export for Day 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f8911d",
      "metadata": {
        "id": "53f8911d"
      },
      "outputs": [],
      "source": [
        "# out_dir = Path('outputs'); out_dir.mkdir(exist_ok=True)\n",
        "# big.to_csv(out_dir / 'latvia_meteo_1925_cleaned_merged.csv', index=False)\n",
        "# # Optional: Parquet for speed/size\n",
        "# # big.to_parquet(out_dir / 'latvia_meteo_1925_cleaned_merged.parquet', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8259a98e",
      "metadata": {
        "id": "8259a98e"
      },
      "source": [
        "## ðŸ”„ Reflection\n",
        "- What kinds of messiness were easier to fix with **Python basics**?\n",
        "- What kinds of messiness required **pandas**?\n",
        "- What are the risks of â€œover-cleaningâ€ or discarding too much data?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}